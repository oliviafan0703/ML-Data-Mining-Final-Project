
---
title: "Final Project Report"
author: "Olivia Fan, Alicia Gong"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, message=F, warning=F, echo=F}
library(knitr)
library(dplyr)
library(tidyverse)
library(e1071)
library(randomForest)
library(caret)
library(ggplot2)
```

```{r include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

# Data Processing

```{r load-data, message = FALSE, echo=F}
cancer<-read_csv("data.csv")%>%
  select(-...33)%>%
  select(-id)%>%
  rename(concave_points_mean='concave points_mean')%>%
  rename(concave_points_worst='concave points_worst')%>%
  rename(concave_points_se='concave points_se'
         )
```


In order to fit SVM on the data, we encode the `diagnosis` variable into a factor variable with level 1 and -1:


```{r}
cancer_binary<-cancer%>%
  mutate(diagnosis_binary=as.factor(ifelse(diagnosis=="M",1,-1)))
```

We partition the data into training and testing sets using a 70-30 percentage split(70% of the original data as the training set, and 30% as the testing set):

```{r}
set.seed(123)
dt = sort(sample(nrow(cancer_binary), nrow(cancer_binary)*.7))
cancer_train<-cancer_binary[dt,]
cancer_test<-cancer_binary[-dt,]
```

# EDA
```{r}
ggplot(data = cancer, mapping = aes(x = diagnosis)) +
  geom_bar()
```
The bar plot shows that there is a larger number of benign than malignant cancer. 

We divide the data into 3 categories according to their features.
```{r}
features_mean= cancer[2:10]
features_se= cancer[11:20]
features_worst= cancer[21:31]
```


```{r}
library(corrplot)
corrplot(cor(features_mean))
```

Major observations: 

- Radius_mean, perimeter_mean, and area_mean are highly correlated.

- Compactness_mean, concavity_mean and concave_points_mean are highly correlated.

# Methodology 

# SVM

## Model Selection (Lasso penalized logistic regression)

```{r}
# Dumy code categorical predictor variables
x <- model.matrix(diagnosis~.-diagnosis_binary, cancer_train)[,-1]
# Convert the outcome (class) to a numerical variable
y <- ifelse(cancer_train$diagnosis == "M", 1, 0)
```


```{r}
library(glmnet)
# Find the best lambda using cross-validation
set.seed(123)
cv.lasso <- cv.glmnet(x, y, alpha = 1, family = "binomial")
plot(cv.lasso)
```

```{r}
cv.lasso$lambda.min
# Final model with lambda.min
lasso.model <- glmnet(x, y, alpha = 1, family = "binomial",
                      lambda = cv.lasso$lambda.min)
coef(lasso.model)
```


## Linear Kernel SVM

We use the predictors selected by the LASSO penalized logistic regression as predictors for the support vector machine model:

```{r}
set.seed(3)

tune.out <- tune(svm, diagnosis_binary ~ concavity_mean+concave_points_mean+radius_se+texture_se+smoothness_se+compactness_se+
fractal_dimension_se+radius_worst+texture_worst+smoothness_worst+concavity_worst+concave_points_worst+symmetry_worst+fractal_dimension_worst, data = cancer_train, kernel = "linear",
                 ranges = list(cost = c(0.001, 0.01, 0.1,
                                        1, 5, 10, 100)))
summary(tune.out)
best_linear_svm <- tune.out$best.model
summary(best_linear_svm)
```

```{r}
ypred <- predict(best_linear_svm, cancer_test)
table(predict = ypred, truth = cancer_test$diagnosis_binary)
classification_error <- 1- sum(ypred == cancer_test$diagnosis_binary)/length(ypred)
classification_error
```

The misclassification rate is 0.0467.


## Radial Kernel SVM

```{r}
set.seed(1)
tune.out <- tune(svm, diagnosis_binary ~ concavity_mean+concave_points_mean+radius_se+texture_se+smoothness_se+compactness_se+
fractal_dimension_se+radius_worst+texture_worst+smoothness_worst+concavity_worst+concave_points_worst+symmetry_worst+fractal_dimension_worst, data = cancer_train,
                 kernel = "radial", 
                 ranges = list(cost = c(0.1, 1, 10, 100, 1000),
                               gamma = c(0.5, 1, 2, 3, 4)))
summary(tune.out)
best_radial_svm <- tune.out$best.model
summary(best_radial_svm)
```

```{r}
ypred <- predict(best_radial_svm, cancer_test)
table(predict = ypred, truth = cancer_test$diagnosis_binary)
classification_error <- 1- sum(ypred == cancer_test$diagnosis_binary)/length(ypred)
```

# Random Forest

```{r}
rf <- randomForest(diagnosis_binary~.-diagnosis, data=cancer_train, proximity=TRUE)
importance(rf)
```

mean:
```{r}
rf_mean <- randomForest(diagnosis_binary~radius_mean + perimeter_mean + area_mean + concavity_mean + concave_points_mean, data = cancer_train, proximity=TRUE)
print(rf_mean)
```
```{r}
pred_mean <- predict(rf_mean, cancer_test)
confusionMatrix(pred_mean, cancer_test$diagnosis_binary)
```

```{r}
rf_worst <- randomForest(diagnosis_binary~radius_worst + perimeter_worst + area_worst + concave_points_worst + concavity_worst, data=cancer_train, proximity=TRUE)
print(rf_worst)
```

```{r}
pred_worst <- predict(rf_worst, cancer_test)
confusionMatrix(pred_worst, cancer_test$diagnosis_binary)
```
